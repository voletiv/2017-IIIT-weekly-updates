<link rel="stylesheet" href="../css/weeklyUpdates.css">

<h2 id="20180406">2018-04-06</h2>

<h3>SUMMARY</h3>

<ol>

<li>EXCHANGE DIALOGUES: Fixed pose problem using cv2.estimateAffine3D. <a href="https://drive.google.com/open?id=1PrU8LlTKh0RdYRuSt6PR6LvHKxtCImCw" target="_blank">RESULTS</a></li>

<p><strong>PROBLEM:</strong> During inference (exchange of dialogues), lip landmarks of the source frame cannot be directly superimposed over the target frame, because the head poses (and hence the mouth poses) don't match!</p>
<p><strong>SOLUTION:</strong> Transform source lip 3D landmarks to target lip 3D landmarks using Affine Tx -> Make lip polygons using the transformed lip landmarks -> Generate new frame</p>

<li>Experimented with lip clusters
</li>

<li>Experimented with Sharwanand, using 2D and 3D landmarks, and data augmentation
  <ul>
  <li>Both 2D and 3D landmarks are erroneous, mostly due to presence of beard.</li>
  <li>Data augmentation does not seem to have provided much advantage.</li>
  </ul>
</li>

<li>Experimented with Mahesh Babu using 3D landmarks, and data augmentation
<ul>
  <li>Data augmentation does not seem to have provided much advantage.</li>
</ul>
</li>

</ol>

<hr />

<h3>1. EXCHANGE DIALOGUES:</h3>

<p><a href="20180406/Movie_Translation_exchange_dialogues.png"><img src="20180406/Movie_Translation_exchange_dialogues.png" alt="NOT FOUND" title="Frame"/></a></p>
<p class=fig>Figure 1: Exchange Dialogues framework</p>

<ul>
<li><a href="https://drive.google.com/open?id=1PrU8LlTKh0RdYRuSt6PR6LvHKxtCImCw" target="_blank">RESULTS</a></li></li>
<li>For training/generation, better results were found by 2D (dlib) than 3D. So for 3D affine Tx of lip landmark points of the form (x, y, z), I consirered (x, y) from <a href="http://dlib.net" target="_blank">dlib</a>, and z from <a href="https://github.com/1adrianb/face-alignment" target="_blank">LS3D-W.</a></li>
<li>Using <a href=https://github.com/voletiv/DeepLearningImplementations/tree/master/pix2pix target="_blank">this</a> Pix2Pix.</li>
</ul>

<hr />

<h3>2. Mahesh Babu LIP CLUSTERS:</h3>

<p><a href="20180406/Lip_clusters/Lip_clusters.png"><img src="20180406/Lip_clusters/Lip_clusters.png" alt="NOT FOUND" title="Frame"/></a></p>

<ul>
<li>Method: <a href="20180406/Lip_clusters/Lip_landmarks_3D_model.html" target="_blank">Jupyter notebook (as HTML)</a>.</li>
<li>Probably ignore 6th and 10th clusters?</li>
<li>TODO: retrieve cluster center as the lip landmarks to draw.</li>
</ul>
https://github.com/1adrianb/face-alignment
<hr />

<h3> 3. Sharwanand </h3>

Didn't work very well.

<ul>

<li><p><strong>REASON</strong>: Landmarks (2D and 3D) of this actor are not very good, due to beard, and erroneous detections.</p></li>
<li><p>Check <a href="https://drive.google.com/open?id=1zUcnGnnXW8p6N_arAwG3nwwnrK_uUH7g">this</a> for examples of issues with 2D and 3D landmarks.</p></li>

</ul>

<h3> Sharwanand experiments </h3>

<table>

  <tr style="font-weight: bold">
    <th>#</th>
    <th>Experiment</th>
    <th>Val output</th>
    <th>Losses</th>
  </tr>

  <tr>
    <td>1</td>
    <td width="100"><textarea rows="10" cols="50" wrap="hard">2D landmarks, batch_size=8, weighted_reconstruction_loss</textarea></td>
    <td height="300" width="500"><a href="20180406/20180404_012006_Sharwanand/20180404_012006_Sharwanand_current_batch_validation.png"><img src="20180406/20180404_012006_Sharwanand/20180404_012006_Sharwanand_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180406/20180404_012006_Sharwanand/20180404_012006_Sharwanand_losses.png"><img src="20180406/20180404_012006_Sharwanand/20180404_012006_Sharwanand_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

  <tr>
    <td>2</td>
    <td width="100"><textarea rows="10" cols="50" wrap="hard">2D landmarks, batch_size=8, weighted_reconstruction_loss, label_smoothing, random_label_flipping (0.1), Minibatch Discrimination</textarea></td>
    <td height="300" width="500"><a href="20180406/20180404_175341_Sharwanand/20180404_175341_Sharwanand_current_batch_validation.png"><img src="20180406/20180404_175341_Sharwanand/20180404_175341_Sharwanand_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180406/20180404_175341_Sharwanand/20180404_175341_Sharwanand_losses.png"><img src="20180406/20180404_175341_Sharwanand/20180404_175341_Sharwanand_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

  <tr>
    <td>3</td>
    <td width="100"><textarea rows="10" cols="50" wrap="hard">3D landmarks, data augmentation (rotation_range=10., width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, horizontal_flip=True), batch_size=8, weighted_reconstruction_loss, label_smoothing, random_label_flipping (0.1), Minibatch Discrimination</textarea></td>
    <td height="300" width="500"><a href="20180406/20180405_023542_Sharwanand_3D/20180405_023542_Sharwanand_3D_current_batch_validation.png"><img src="20180406/20180405_023542_Sharwanand_3D/20180405_023542_Sharwanand_3D_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180406/20180405_023542_Sharwanand_3D/20180405_023542_Sharwanand_3D_losses.png"><img src="20180406/20180405_023542_Sharwanand_3D/20180405_023542_Sharwanand_3D_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

</table>

<hr />

<h3> 4. Mahesh Babu & 3D landmarks</h3>

<ul>
<li>Pretty good.</li>
<li>Only limitation seems to be quality of lip landmarks (Check images in experiments below).</li>
<li>Data augmentation does not seem to provide much advantage.</li>
</ul>

<h3> Mahesh Babu 3D experiments </h3>

<table>

  <tr style="font-weight: bold">
    <th>#</th>
    <th>Experiment</th>
    <th>Val output</th>
    <th>Losses</th>
  </tr>

  <tr>
    <td>2</td>
    <td width="100"><textarea rows="10" cols="50" wrap="hard">3D landmarks, data augmentation (rotation_range=10., width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, horizontal_flip=True), batch_size=8, weighted_reconstruction_loss, label_smoothing, random_label_flipping (0.1), Minibatch Discrimination</textarea></td>
    <td height="300" width="500"><a href="20180406/20180405_102215_Mahesh_Babu_3D/20180405_102215_Mahesh_Babu_3D_current_batch_validation.png"><img src="20180406/20180405_102215_Mahesh_Babu_3D/20180405_102215_Mahesh_Babu_3D_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180406/20180405_102215_Mahesh_Babu_3D/20180405_102215_Mahesh_Babu_3D_losses.png"><img src="20180406/20180405_102215_Mahesh_Babu_3D/20180405_102215_Mahesh_Babu_3D_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

  <tr>
    <td>2</td>
    <td width="100"><textarea rows="10" cols="50" wrap="hard">3D landmarks, batch_size=8, weighted_reconstruction_loss, label_smoothing, random_label_flipping (0.1), Minibatch Discrimination</textarea></td>
    <td height="300" width="500"><a href="20180406/20180405_171152_Mahesh_Babu_3D/20180405_171152_Mahesh_Babu_3D_current_batch_validation.png"><img src="20180406/20180405_171152_Mahesh_Babu_3D/20180405_171152_Mahesh_Babu_3D_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180406/20180405_171152_Mahesh_Babu_3D/20180405_171152_Mahesh_Babu_3D_losses.png"><img src="20180406/20180405_171152_Mahesh_Babu_3D/20180405_171152_Mahesh_Babu_3D_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

</table>

<h3>Best from previous page:</h3>

<table>

  <tr style="font-weight: bold">
    <th>#</th>
    <th>Experiment</th>
    <th>Val output</th>
    <th>Losses</th>
  </tr>

  <tr>
    <td>3</td>
    <td width="100"><textarea cols="50" wrap="hard">batch_size = 8, weighted_reconstruction_loss, label_smoothing, random_label_flipping (0.1), Minibatch Discrimination</textarea></td>
    <td height="300" width="500"><a href="20180315/Exp3/20180314_152941_Mahesh_Babu_black_mouth_polygons_current_batch_validation.png"><img src="20180315/Exp3/20180314_152941_Mahesh_Babu_black_mouth_polygons_current_batch_validation.png" alt="NOT FOUND" title="Frame"/></a></td>  
    <td height="300" width="500"><a href="20180315/Exp3/20180314_152941_Mahesh_Babu_black_mouth_polygons_losses.png"><img src="20180315/Exp3/20180314_152941_Mahesh_Babu_black_mouth_polygons_losses.png" alt="NOT FOUND" title="Frame"/></a></td>
  </tr>

</table>

<hr />

<ul>

<li>Idea: Train on LRW, fine-tune on Indian_Movie_Translation dataset</li>

</ul>

<hr />

<h4> Dataset Collection - automated pipeline: (put on hold) </h4>

<p><a href="20180223/Data_collection_pipeline.png"><img src="20180223/Data_collection_pipeline.png" alt="NOT FOUND" title="Frame"/></a></p>

<ul>
<li>Extract audio, isolate voice/speech using Audacity [<a href="http://www.audacityteam.org/">GitHub</a>]</li>
<li>Perform Voice Activity Detection using WebRTC [<a href="https://github.com/wiseman/py-webrtcvad">GitHub</a>]</li>
<li>Check for speaker through audio features, or facial features via [<a href="https://github.com/rcmalli/keras-vggface">VGG Face</a>]</li>
<li>Annotate dialogues in ITRANS (possible use of <a href="liv.ai">liv.ai</a>)</li>
</ul>




